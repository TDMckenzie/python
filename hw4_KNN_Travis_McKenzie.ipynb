{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5cd61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1448f33-0ddc-457a-a40e-8327b48674fc",
   "metadata": {},
   "source": [
    "# Question 0\n",
    "\n",
    "Using the penguins dataset below, if you put all Adelie penguins from the dataset living on Torgersen island on a scale together at the same time, how much would they weigh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3a3d9299-7713-4459-9eaf-d4119435668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "penguins = sns.load_dataset('penguins')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1424f0d-e92a-4de5-aef2-4e96500babe0",
   "metadata": {},
   "source": [
    "solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eff26fc9-946c-4d96-8b90-36982769edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5c0ea7cf-2711-4c21-96df-eef95262bf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     body_mass_g\n",
      "species   island                \n",
      "Adelie    Biscoe        163225.0\n",
      "          Dream         206550.0\n",
      "          Torgersen     189025.0\n",
      "Chinstrap Dream         253850.0\n",
      "Gentoo    Biscoe        624350.0\n"
     ]
    }
   ],
   "source": [
    "atpenguins= penguins.groupby(['species','island'])[['body_mass_g']].sum()\n",
    "print(atpenguins)\n",
    "\n",
    "##The total weight of the Adelie penguins on Torgersen island within this dataset would be 189,025 grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df1b2d",
   "metadata": {},
   "source": [
    "# Let's play with this dataset! A different kind of wine data.\n",
    "\n",
    "The features are 13 chemical (numerical) attributes of 178 different wines. These wines are made by 3 different producers in Italy, which is the dependent variable: producer 0, 1, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ff72f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c3917f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 178\n",
      ":Number of Attributes: 13 numeric, predictive attributes and the class\n",
      ":Attribute Information:\n",
      "    - Alcohol\n",
      "    - Malic acid\n",
      "    - Ash\n",
      "    - Alcalinity of ash\n",
      "    - Magnesium\n",
      "    - Total phenols\n",
      "    - Flavanoids\n",
      "    - Nonflavanoid phenols\n",
      "    - Proanthocyanins\n",
      "    - Color intensity\n",
      "    - Hue\n",
      "    - OD280/OD315 of diluted wines\n",
      "    - Proline\n",
      "    - class:\n",
      "        - class_0\n",
      "        - class_1\n",
      "        - class_2\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "============================= ==== ===== ======= =====\n",
      "                                Min   Max   Mean     SD\n",
      "============================= ==== ===== ======= =====\n",
      "Alcohol:                      11.0  14.8    13.0   0.8\n",
      "Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "Ash:                          1.36  3.23    2.36  0.27\n",
      "Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "Magnesium:                    70.0 162.0    99.7  14.3\n",
      "Total Phenols:                0.98  3.88    2.29  0.63\n",
      "Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "Hue:                          0.48  1.71    0.96  0.23\n",
      "OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "Proline:                       278  1680     746   315\n",
      "============================= ==== ===== ======= =====\n",
      "\n",
      ":Missing Attribute Values: None\n",
      ":Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      ":Creator: R.A. Fisher\n",
      ":Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      ":Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners:\n",
      "\n",
      "Forina, M. et al, PARVUS -\n",
      "An Extendible Package for Data Exploration, Classification and Correlation.\n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science.\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "(1) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "Comparison of Classifiers in High Dimensional Settings,\n",
      "Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of\n",
      "Mathematics and Statistics, James Cook University of North Queensland.\n",
      "(Also submitted to Technometrics).\n",
      "\n",
      "The data was used with many others for comparing various\n",
      "classifiers. The classes are separable, though only RDA\n",
      "has achieved 100% correct classification.\n",
      "(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data))\n",
      "(All results using the leave-one-out technique)\n",
      "\n",
      "(2) S. Aeberhard, D. Coomans and O. de Vel,\n",
      "\"THE CLASSIFICATION PERFORMANCE OF RDA\"\n",
      "Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of\n",
      "Mathematics and Statistics, James Cook University of North Queensland.\n",
      "(Also submitted to Journal of Chemometrics).\n",
      "\n",
      "|details-end|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e10d9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4311e522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "40ff8ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1afca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd919c05",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Are there any missing values in X? If so, in which columns and how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "64251b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         0\n",
       "malic_acid                      0\n",
       "ash                             0\n",
       "alcalinity_of_ash               0\n",
       "magnesium                       0\n",
       "total_phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid_phenols            0\n",
       "proanthocyanins                 0\n",
       "color_intensity                 0\n",
       "hue                             0\n",
       "od280/od315_of_diluted_wines    0\n",
       "proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum() | X.eq('').sum()\n",
    "\n",
    "#There are no missing values in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b656f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df56809e",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Add a feature called 'above_avg_alcohol' that is 1 if the alcohol content is above the average for the dataset, and 0 otherwise.\n",
    "\n",
    "Add any other features you think might be good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc05393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>above_avg_alcohol</th>\n",
       "      <th>above_ash</th>\n",
       "      <th>above_avg_alc_of_ash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.420000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>650.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>13.50</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2.62</td>\n",
       "      <td>24.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.30</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>12.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.47</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.520000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>675.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>12.58</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.40</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.55</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>13.17</td>\n",
       "      <td>5.19</td>\n",
       "      <td>2.32</td>\n",
       "      <td>22.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.55</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.48</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.010000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>12.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.73</td>\n",
       "      <td>880.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>13.48</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.64</td>\n",
       "      <td>22.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2.29</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.78</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>12.36</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.04</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.58</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.580000</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>570.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.35</td>\n",
       "      <td>18.5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.580000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>615.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>13.73</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.620000</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.75</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>13.45</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>23.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.46</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.56</td>\n",
       "      <td>695.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>12.82</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10.260000</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>685.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>13.58</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.69</td>\n",
       "      <td>24.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.54</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.80</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>630.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>12.20</td>\n",
       "      <td>3.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.73</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.83</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>12.77</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.28</td>\n",
       "      <td>19.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.899999</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.63</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>14.16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.24</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.71</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "148    13.32        3.24  2.38               21.5       92.0           1.93   \n",
       "149    13.08        3.90  2.36               21.5      113.0           1.41   \n",
       "150    13.50        3.12  2.62               24.0      123.0           1.40   \n",
       "151    12.79        2.67  2.48               22.0      112.0           1.48   \n",
       "152    13.11        1.90  2.75               25.5      116.0           2.20   \n",
       "153    13.23        3.30  2.28               18.5       98.0           1.80   \n",
       "154    12.58        1.29  2.10               20.0      103.0           1.48   \n",
       "155    13.17        5.19  2.32               22.0       93.0           1.74   \n",
       "156    13.84        4.12  2.38               19.5       89.0           1.80   \n",
       "157    12.45        3.03  2.64               27.0       97.0           1.90   \n",
       "158    14.34        1.68  2.70               25.0       98.0           2.80   \n",
       "159    13.48        1.67  2.64               22.5       89.0           2.60   \n",
       "160    12.36        3.83  2.38               21.0       88.0           2.30   \n",
       "161    13.69        3.26  2.54               20.0      107.0           1.83   \n",
       "162    12.85        3.27  2.58               22.0      106.0           1.65   \n",
       "163    12.96        3.45  2.35               18.5      106.0           1.39   \n",
       "164    13.78        2.76  2.30               22.0       90.0           1.35   \n",
       "165    13.73        4.36  2.26               22.5       88.0           1.28   \n",
       "166    13.45        3.70  2.60               23.0      111.0           1.70   \n",
       "167    12.82        3.37  2.30               19.5       88.0           1.48   \n",
       "168    13.58        2.58  2.69               24.5      105.0           1.55   \n",
       "169    13.40        4.60  2.86               25.0      112.0           1.98   \n",
       "170    12.20        3.03  2.32               19.0       96.0           1.25   \n",
       "171    12.77        2.39  2.28               19.5       86.0           1.39   \n",
       "172    14.16        2.51  2.48               20.0       91.0           1.68   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "148        0.76                  0.45             1.25         8.420000  0.55   \n",
       "149        1.39                  0.34             1.14         9.400000  0.57   \n",
       "150        1.57                  0.22             1.25         8.600000  0.59   \n",
       "151        1.36                  0.24             1.26        10.800000  0.48   \n",
       "152        1.28                  0.26             1.56         7.100000  0.61   \n",
       "153        0.83                  0.61             1.87        10.520000  0.56   \n",
       "154        0.58                  0.53             1.40         7.600000  0.58   \n",
       "155        0.63                  0.61             1.55         7.900000  0.60   \n",
       "156        0.83                  0.48             1.56         9.010000  0.57   \n",
       "157        0.58                  0.63             1.14         7.500000  0.67   \n",
       "158        1.31                  0.53             2.70        13.000000  0.57   \n",
       "159        1.10                  0.52             2.29        11.750000  0.57   \n",
       "160        0.92                  0.50             1.04         7.650000  0.56   \n",
       "161        0.56                  0.50             0.80         5.880000  0.96   \n",
       "162        0.60                  0.60             0.96         5.580000  0.87   \n",
       "163        0.70                  0.40             0.94         5.280000  0.68   \n",
       "164        0.68                  0.41             1.03         9.580000  0.70   \n",
       "165        0.47                  0.52             1.15         6.620000  0.78   \n",
       "166        0.92                  0.43             1.46        10.680000  0.85   \n",
       "167        0.66                  0.40             0.97        10.260000  0.72   \n",
       "168        0.84                  0.39             1.54         8.660000  0.74   \n",
       "169        0.96                  0.27             1.11         8.500000  0.67   \n",
       "170        0.49                  0.40             0.73         5.500000  0.66   \n",
       "171        0.51                  0.48             0.64         9.899999  0.57   \n",
       "172        0.70                  0.44             1.24         9.700000  0.62   \n",
       "173        0.61                  0.52             1.06         7.700000  0.64   \n",
       "174        0.75                  0.43             1.41         7.300000  0.70   \n",
       "175        0.69                  0.43             1.35        10.200000  0.59   \n",
       "176        0.68                  0.53             1.46         9.300000  0.60   \n",
       "177        0.76                  0.56             1.35         9.200000  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  above_avg_alcohol  above_ash  \\\n",
       "148                          1.62    650.0                  1          1   \n",
       "149                          1.33    550.0                  1          0   \n",
       "150                          1.30    500.0                  1          1   \n",
       "151                          1.47    480.0                  0          1   \n",
       "152                          1.33    425.0                  1          1   \n",
       "153                          1.51    675.0                  1          0   \n",
       "154                          1.55    640.0                  0          0   \n",
       "155                          1.48    725.0                  1          0   \n",
       "156                          1.64    480.0                  1          1   \n",
       "157                          1.73    880.0                  0          1   \n",
       "158                          1.96    660.0                  1          1   \n",
       "159                          1.78    620.0                  1          1   \n",
       "160                          1.58    520.0                  0          1   \n",
       "161                          1.82    680.0                  1          1   \n",
       "162                          2.11    570.0                  0          1   \n",
       "163                          1.75    675.0                  0          0   \n",
       "164                          1.68    615.0                  1          0   \n",
       "165                          1.75    520.0                  1          0   \n",
       "166                          1.56    695.0                  1          1   \n",
       "167                          1.75    685.0                  0          0   \n",
       "168                          1.80    750.0                  1          1   \n",
       "169                          1.92    630.0                  1          1   \n",
       "170                          1.83    510.0                  0          0   \n",
       "171                          1.63    470.0                  0          0   \n",
       "172                          1.71    660.0                  1          1   \n",
       "173                          1.74    740.0                  1          1   \n",
       "174                          1.56    750.0                  1          1   \n",
       "175                          1.56    835.0                  1          0   \n",
       "176                          1.62    840.0                  1          1   \n",
       "177                          1.60    560.0                  1          1   \n",
       "\n",
       "     above_avg_alc_of_ash  \n",
       "148                     1  \n",
       "149                     1  \n",
       "150                     1  \n",
       "151                     1  \n",
       "152                     1  \n",
       "153                     0  \n",
       "154                     1  \n",
       "155                     1  \n",
       "156                     1  \n",
       "157                     1  \n",
       "158                     1  \n",
       "159                     1  \n",
       "160                     1  \n",
       "161                     1  \n",
       "162                     1  \n",
       "163                     0  \n",
       "164                     1  \n",
       "165                     1  \n",
       "166                     1  \n",
       "167                     1  \n",
       "168                     1  \n",
       "169                     1  \n",
       "170                     0  \n",
       "171                     1  \n",
       "172                     1  \n",
       "173                     1  \n",
       "174                     1  \n",
       "175                     1  \n",
       "176                     1  \n",
       "177                     1  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['above_avg_alcohol']=np.where(X['alcohol'] > X['alcohol'].mean(), 1,0)\n",
    "#X['above_malic_acid']=np.where(X['malic_acid'] > X['malic_acid'].mean(), 1,0)\n",
    "#X['above_avg_magnesium']=np.where(X['magnesium'] > X['magnesium'].mean(), 1,0)\n",
    "#X['above_avg_proline']=np.where(X['proline'] > X['proline'].mean(), 1,0)\n",
    "X['above_ash']=np.where(X['ash'] > X['ash'].mean(), 1,0)\n",
    "X['above_avg_alc_of_ash']=np.where(X['alcalinity_of_ash'] > X['alcalinity_of_ash'].mean(), 1,0)\n",
    "X.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a7061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77e294a6",
   "metadata": {},
   "source": [
    "### Question 3 (WITH BONUS POINT OPPORTUNITY!)\n",
    "\n",
    "Create a KNN model to predict y based on whichever features from X, including any new ones you created. Print the confusion matrix and accuracy on X and y (so on its own training data). \n",
    "\n",
    "Full credit for the question if it works and you use KNN to predict y given X. However, extra credit to the person with the highest accuracy score! It may even help to drop some confounding features. Or to tweak K. Or to engineer some other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8ba4143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fb9ae29c-7898-4f0b-95de-e33abdf20c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f4a83427-3450-47a1-9224-f0ef89e89a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aa75d79e-0799-4133-8d8c-7013964de913",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d15bd26f-0304-4b6b-8491-c425891c65af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2,\n",
       "       0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2d61c7c3-23bc-40cb-ab02-338dd0768f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8707865168539326\n",
      "0.8049082678103407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "#accuracy\n",
    "print(sum(y==y_pred)/len(y))\n",
    "#cohen_kappa_score\n",
    "print(cohen_kappa_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5c6b146b-ff5a-4ad5-b58a-8762d0b672f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  0,  4],\n",
       "       [ 4, 59,  8],\n",
       "       [ 1,  6, 41]], dtype=int64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76e2ed-d7f9-4a7e-8a23-474353d4bc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b2a5450d-1e5f-400b-8ffd-4d4a4312a993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Accuracy:  0.8707865168539326\n",
      "4 Accuracy:  0.8314606741573034\n",
      "5 Accuracy:  0.7865168539325843\n",
      "6 Accuracy:  0.7752808988764045\n",
      "7 Accuracy:  0.7528089887640449\n",
      "8 Accuracy:  0.7752808988764045\n",
      "9 Accuracy:  0.7752808988764045\n"
     ]
    }
   ],
   "source": [
    "for k_param in range(3, 10):\n",
    "    model = KNeighborsClassifier(n_neighbors=k_param)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    print(k_param, 'Accuracy: ', sum(y == y_pred) / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b11c99c9-2965-427b-a3b1-d520f28196d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##accuracy of 0.87 with 3 neighbors was the best outcome I was able to get after testing a variety of features.  Was not able to get as\n",
    "##adventurous as I would have liked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c17a2d",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Mistakes! Can you identify the rows in X and y that your model mis-classified? Show how to create a dataframe with just the mistake rows.\n",
    "\n",
    "Then: make a single scatterplot of both your full dataset and only your mistakes against the 'alcohol' and 'flavanoids' columns. Your scatterplot should somehow make it easy to identify the mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "71e47129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                           506.990000\n",
       "malic_acid                        100.290000\n",
       "ash                                93.800000\n",
       "alcalinity_of_ash                 812.100000\n",
       "magnesium                        4071.000000\n",
       "total_phenols                      82.550000\n",
       "flavanoids                         61.160000\n",
       "nonflavanoid_phenols               15.600000\n",
       "proanthocyanins                    59.660000\n",
       "color_intensity                   213.039999\n",
       "hue                                34.606000\n",
       "od280/od315_of_diluted_wines       92.080000\n",
       "proline                         27211.000000\n",
       "above_avg_alcohol                  15.000000\n",
       "above_ash                          16.000000\n",
       "above_avg_alc_of_ash               26.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[y != y_pred].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dabedace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='alcohol', ylabel='flavanoids'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(X, x='alcohol', y='flavanoids', c='lightgray')\n",
    "sns.scatterplot(X.loc[y != y_pred], x='alcohol', y='flavanoids', c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd03a84-29fe-4993-9088-9f5f697e02dc",
   "metadata": {},
   "source": [
    "###  Question 5: Ethics\n",
    "\n",
    "Suppose you are designing an ML model that will target a new ad campaign to certain consumers. The ad campaign will offer a substantial discount on whatever your employer is selling. What concerns and thoughts would you have right up front about ensuring fairness from your ML model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2137da-37db-486c-b1a4-285d145718cb",
   "metadata": {},
   "source": [
    "## Q5 - Answer\n",
    "There are a lot of factors to consider here.  Whatever data your model is based on will incorporate some form of bias.  The model will have been trained on your available data which could give it some tendencies towards certain demographics.  This could give an unfair discount to certain groups and disadvantage other groups of the discount simply because they were targeted by the biases inherent in the data and thus the model.\n",
    "\n",
    "There could also be injurious exposures towards certain groups, particularly if the product is some form of vice, like gambling, drugs etc.  One group would be receiving increased risk exposures as a result of being targeted with the discounts as a product of using the model.\n",
    "\n",
    "One way to attempt to mitigate this would be to attempt to re-evaluate the model from a fairness perspective.  It also might be worth considering the removal of certain pieces of data to reduce the tendency of the data to target certain individuals.  It would be worth evaluating the performance against that information to ensure that the model is not optimizing itself towards any particular group, or away from any particular group in a manner that is unfair and could be harmful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a1797-c50d-4d87-b537-6efdc4e000eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
